{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHH-9yTR-Ys_"
      },
      "source": [
        "dataset link: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgijw6vX-UHe"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9IWe43i-hCS"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PIfZf0ZGGYr"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AqaSmTAGVHD"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpaXMmrTG-eO"
      },
      "outputs": [],
      "source": [
        "! unzip -q /content/creditcardfraud.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pECzyPQsTdMe"
      },
      "source": [
        "# Loading python packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsfTxemjUS8f"
      },
      "source": [
        "**Packages for data loading, data analysis, and data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8bdSHH5HzCC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from pandas import read_csv, set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJDM9pqfUdpg"
      },
      "source": [
        "**Packages for model evaluation and classification models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhj8NFg0UtDn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfdhFiKhUzfL"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLNZ3XFBVKF3"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQzOvqBMVkaJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZO8eTlWVtKl"
      },
      "source": [
        "**Packages for deep learning model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2BNjseTWgBN"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPaUTZ28VsVt"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.9.1\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbb2-e2Qb5Ol"
      },
      "outputs": [],
      "source": [
        "from pickle import dump\n",
        "from pickle import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2A5WffHcDZD"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('creditcard.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owIvkUvTcIjy"
      },
      "source": [
        "## Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0VYVEvwcQU1"
      },
      "outputs": [],
      "source": [
        "#shape\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPafkiDgcUSq"
      },
      "outputs": [],
      "source": [
        "#peek at data\n",
        "set_option('display.width', 100)\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ONxlSADc25j"
      },
      "outputs": [],
      "source": [
        "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
        "print(dataset.Class.value_counts().rename(index = class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QbR9SyedeBL"
      },
      "source": [
        "***Data Visualization: Since the feature descriptions are not provided,visualizing the data will not lead to much insight. This step will be skipped in this case study***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_1MGrUad5sv"
      },
      "source": [
        "***Data Preparation: This data is kaggle and is already in a cleaned format without any empty rows or columns. Data cleaning or categorization is unnecessary***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_07hv5MeNbw"
      },
      "source": [
        "# **Evaluate Models: **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWpqJTSredcu"
      },
      "source": [
        "**Train-Test split and evaluation metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lrXWF62d15x"
      },
      "outputs": [],
      "source": [
        "Y = dataset['Class']\n",
        "X = dataset.loc[:, dataset.columns != 'Class']\n",
        "validation_size = 0.20\n",
        "seed = 7\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_OJRYJPewUu"
      },
      "outputs": [],
      "source": [
        "# test options for classifications\n",
        "\n",
        "num_folds = 10\n",
        "scoring = 'accuracy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhrJKmpZilh7"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(( 'LR', LogisticRegression()))\n",
        "models.append(( 'LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(( 'KNN', KNeighborsClassifier()))\n",
        "models.append(( 'CART', DecisionTreeClassifier()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfxvp2hglLW7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIwDOZtZleOC"
      },
      "outputs": [],
      "source": [
        "# compare algorithm\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX4PG21Tubad"
      },
      "outputs": [],
      "source": [
        "# prepare model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH0joa3CuRk6"
      },
      "outputs": [],
      "source": [
        "#estimate accuracy on validation set\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYXEYyzavbuu"
      },
      "outputs": [],
      "source": [
        "df_cm = pd.DataFrame(confusion_matrix(Y_validation, predictions), columns=np.unique(Y_validation), index = np.unique(Y_validation))\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJWxQDngwTba"
      },
      "source": [
        "**Model Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tff2Gz8SwfwO"
      },
      "source": [
        "**Model tuning by choosing the correct evaluation metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKq7PSzUwCUO"
      },
      "outputs": [],
      "source": [
        "scoring = 'recall'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6xyuGRrw4UC"
      },
      "source": [
        "**let us spot-check some basic classification algorithms for recall**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3wt8TKgwvA3"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(( 'LR', LogisticRegression()))\n",
        "models.append(( 'LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(( 'KNN', KNeighborsClassifier()))\n",
        "models.append(( 'CART', DecisionTreeClassifier()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYve_r-Tw3RD"
      },
      "source": [
        "**Running cross validation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Euqnz24uxOGf"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring= scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw3xlupLz41Q"
      },
      "outputs": [],
      "source": [
        "#prepare model\n",
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "#estimate accuracy on validation set\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDgvxvrG6fLi"
      },
      "source": [
        "**Model tuning- balancing the sample by random under-sampling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZJ7s5Ys6O_j"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([X_train, Y_train], axis=1)\n",
        "# amount of fraud classes 492 rows.\n",
        "fraud_df = df.loc[df['Class'] == 1]\n",
        "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
        "\n",
        "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
        "\n",
        "# shuffle dataframe rows\n",
        "df_new = normal_distributed_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# split out validation dataset for the end\n",
        "Y_train_new = df_new['Class']\n",
        "X_train_new = df_new.loc[:, df_new.columns != 'Class']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LRaDNm17al6"
      },
      "source": [
        "**Let us look at the distribution of the classes in the dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LFmwTGG7YQr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print('Distribution of the Classes in the subsample dataset')\n",
        "print(df_new['Class'].value_counts(), len(df_new))\n",
        "\n",
        "sns.countplot(x='Class', data=df_new)\n",
        "pyplot.title('Equally Distributed Classes', fontsize=14)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJoY6ae08iuv"
      },
      "outputs": [],
      "source": [
        "#setting the evaluation metric\n",
        "scoring = 'accuracy'\n",
        "\n",
        "#spot-check the algorithms\n",
        "models = []\n",
        "models.append(( 'LR', LogisticRegression()))\n",
        "models.append(( 'LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(( 'KNN', KNeighborsClassifier()))\n",
        "models.append(( 'CART', DecisionTreeClassifier()))\n",
        "models.append(( 'NB', GaussianNB()))\n",
        "models.append(( 'SVM', SVC()))\n",
        "\n",
        "#neural network\n",
        "models.append(( 'NN', MLPClassifier()))\n",
        "\n",
        "#Ensemble models\n",
        "#boosting methods\n",
        "models.append(('AB', AdaBoostClassifier()))\n",
        "models.append(('GBM', GradientBoostingClassifier()))\n",
        "\n",
        "#bagging methods\n",
        "models.append(('RF', RandomForestClassifier()))\n",
        "models.append(('ET', ExtraTreesClassifier()))\n",
        "\n",
        "#bagging methods\n",
        "models.append(('RF', RandomForestClassifier()))\n",
        "models.append(('ET', ExtraTreesClassifier()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV8spPmINWjo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n0XLLTg963d"
      },
      "source": [
        "**Keras-based deep learning model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOyRuAjc9p9g"
      },
      "outputs": [],
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create_model(neurons=12, activation='relu', learn_rate = 0.01, momentum=0):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(X_train.shape[1], input_dim= X_train.shape[1], activation=activation))\n",
        "    model.add(Dense(32,activation=activation))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    #compile model\n",
        "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "models.append(('DNN', KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "erz-zxr8OdWA",
        "outputId": "2bf4435a-5ff7-4ea4-c536-e1623bbef696"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: 0.9990 (0.0002)\n",
            "LDA: 0.9994 (0.0001)\n",
            "KNN: 0.9984 (0.0001)\n",
            "CART: 0.9992 (0.0002)\n",
            "NB: 0.9929 (0.0005)\n",
            "SVM: 0.9983 (0.0000)\n",
            "NN: 0.9978 (0.0018)\n",
            "AB: 0.9991 (0.0002)\n",
            "GBM: 0.9987 (0.0003)\n",
            "RF: 0.9996 (0.0001)\n",
            "ET: 0.9995 (0.0001)\n",
            "RF: 0.9996 (0.0001)\n",
            "ET: 0.9995 (0.0001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
        "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    print(f\"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})\")\n",
        "\n",
        "# Compare Algorithms\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.boxplot(results, labels=names)\n",
        "plt.title('Algorithm Comparison')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOvpFmDP_tSN"
      },
      "outputs": [],
      "source": [
        "#Grid Search: GradientBoosting Tuning\n",
        "n_estimators = [20,180,1000]\n",
        "max_depth = [2,3,5]\n",
        "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
        "model = GradientBoostingClassifier()\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "grid_result = grid.fit(X_train_new, Y_train_new)\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XldywaRPH2JM"
      },
      "outputs": [],
      "source": [
        "# prepare model\n",
        "\n",
        "model = GradientBoostingClassifier(max_depth=5, n_estimators=180)\n",
        "model.fit(X_train_new, Y_train_new)\n",
        "\n",
        "#estimate accuracy on Original validation set\n",
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}